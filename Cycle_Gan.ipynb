{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPsRDcoe+Q7o/Va1nEWAPbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanisha2202/ML-CycleGan/blob/main/Cycle_Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47xJKbOQpM6z",
        "outputId": "424a588e-bc2a-46b3-fe07-15b3df885018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m204.8/207.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow labml labml-nn labml-helpers --quiet\n",
        "import itertools\n",
        "import random\n",
        "import zipfile\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import InterpolationMode\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from labml import lab, tracker, experiment, monit\n",
        "from labml.configs import BaseConfigs\n",
        "from labml.utils.download import download_file\n",
        "from labml.utils.pytorch import get_modules\n",
        "from labml_helpers.device import DeviceConfigs\n",
        "from labml_helpers.module import Module\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GeneratorResNet(Module):\n",
        "    \"\"\"\n",
        "    The generator is a residual network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_channels: int, n_residual_blocks: int):\n",
        "        super().__init__()\n",
        "        # This first block runs a $7\\times7$ convolution and maps the image to\n",
        "        # a feature map.\n",
        "        # The output feature map has the same height and width because we have\n",
        "        # a padding of $3$.\n",
        "        # Reflection padding is used because it gives better image quality at edges.\n",
        "        #\n",
        "        # `inplace=True` in `ReLU` saves a little bit of memory.\n",
        "        out_features = 64\n",
        "        layers = [\n",
        "            nn.Conv2d(input_channels, out_features, kernel_size=7, padding=3, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # We down-sample with two $3 \\times 3$ convolutions\n",
        "        # with stride of 2\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            layers += [\n",
        "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # We take this through `n_residual_blocks`.\n",
        "        # This module is defined below.\n",
        "        for _ in range(n_residual_blocks):\n",
        "            layers += [ResidualBlock(out_features)]\n",
        "\n",
        "        # Then the resulting feature map is up-sampled\n",
        "        # to match the original image height and width.\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            layers += [\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=1, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Finally we map the feature map to an RGB image\n",
        "        layers += [nn.Conv2d(out_features, input_channels, 7, padding=3, padding_mode='reflect'), nn.Tanh()]\n",
        "\n",
        "        # Create a sequential module with the layers\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # Initialize weights to $\\mathcal{N}(0, 0.2)$\n",
        "        self.apply(weights_init_normal)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "30IUUu-PqLNc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(Module):\n",
        "    \"\"\"\n",
        "    This is the residual block, with two convolution layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, padding=1, padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return x + self.block(x)"
      ],
      "metadata": {
        "id": "yns6qFY3qSw8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Module):\n",
        "    \"\"\"\n",
        "    This is the discriminator.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_shape: Tuple[int, int, int]):\n",
        "        super().__init__()\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # Output of the discriminator is also a map of probabilities,\n",
        "        # whether each region of the image is real or generated\n",
        "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            # Each of these blocks will shrink the height and width by a factor of 2\n",
        "            DiscriminatorBlock(channels, 64, normalize=False),\n",
        "            DiscriminatorBlock(64, 128),\n",
        "            DiscriminatorBlock(128, 256),\n",
        "            DiscriminatorBlock(256, 512),\n",
        "            # Zero pad on top and left to keep the output height and width same\n",
        "            # with the $4 \\times 4$ kernel\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n",
        "        )\n",
        "\n",
        "        # Initialize weights to $\\mathcal{N}(0, 0.2)$\n",
        "        self.apply(weights_init_normal)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.layers(img)"
      ],
      "metadata": {
        "id": "zJTVeUvKqXs4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DiscriminatorBlock(Module):\n",
        "    \"\"\"\n",
        "    This is the discriminator block module.\n",
        "    It does a convolution, an optional normalization, and a leaky ReLU.\n",
        "\n",
        "    It shrinks the height and width of the input feature map by half.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_filters: int, out_filters: int, normalize: bool = True):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=2, padding=1)]\n",
        "        if normalize:\n",
        "            layers.append(nn.InstanceNorm2d(out_filters))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "sllajqWjqgU8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    \"\"\"\n",
        "    Initialize convolution layer weights to $\\mathcal{N}(0, 0.2)$\n",
        "    \"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n"
      ],
      "metadata": {
        "id": "uHRgfJASqnFi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path: str):\n",
        "    \"\"\"\n",
        "    Load an image and change to RGB if in grey-scale.\n",
        "    \"\"\"\n",
        "    image = Image.open(path)\n",
        "    if image.mode != 'RGB':\n",
        "        image = Image.new(\"RGB\", image.size).paste(image)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "ACnQ3sZTqsmX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ### Dataset to load images\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def download(dataset_name: str):\n",
        "        \"\"\"\n",
        "        #### Download dataset and extract data\n",
        "        \"\"\"\n",
        "        # URL\n",
        "        url = f'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{dataset_name}.zip'\n",
        "        # Download folder\n",
        "        root = lab.get_data_path() / 'cycle_gan'\n",
        "        if not root.exists():\n",
        "            root.mkdir(parents=True)\n",
        "        # Download destination\n",
        "        archive = root / f'{dataset_name}.zip'\n",
        "        # Download file (generally ~100MB)\n",
        "        download_file(url, archive)\n",
        "        # Extract the archive\n",
        "        with zipfile.ZipFile(archive, 'r') as f:\n",
        "            f.extractall(root)\n",
        "\n",
        "    def __init__(self, dataset_name: str, transforms_, mode: str):\n",
        "        \"\"\"\n",
        "        #### Initialize the dataset\n",
        "\n",
        "        * `dataset_name` is the name of the dataset\n",
        "        * `transforms_` is the set of image transforms\n",
        "        * `mode` is either `train` or `test`\n",
        "        \"\"\"\n",
        "        # Dataset path\n",
        "        root = lab.get_data_path() / 'cycle_gan' / dataset_name\n",
        "        # Download if missing\n",
        "        if not root.exists():\n",
        "            self.download(dataset_name)\n",
        "\n",
        "        # Image transforms\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "\n",
        "        # Get image paths\n",
        "        path_a = root / f'{mode}A'\n",
        "        path_b = root / f'{mode}B'\n",
        "        self.files_a = sorted(str(f) for f in path_a.iterdir())\n",
        "        self.files_b = sorted(str(f) for f in path_b.iterdir())\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Return a pair of images.\n",
        "        # These pairs get batched together, and they do not act like pairs in training.\n",
        "        # So it is kind of ok that we always keep giving the same pair.\n",
        "        return {\"x\": self.transform(load_image(self.files_a[index % len(self.files_a)])),\n",
        "                \"y\": self.transform(load_image(self.files_b[index % len(self.files_b)]))}\n",
        "\n",
        "    def __len__(self):\n",
        "        # Number of images in the dataset\n",
        "        return max(len(self.files_a), len(self.files_b))"
      ],
      "metadata": {
        "id": "JnYxTzL6q10v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"\n",
        "    ### Replay Buffer\n",
        "\n",
        "    Replay buffer is used to train the discriminator.\n",
        "    Generated images are added to the replay buffer and sampled from it.\n",
        "\n",
        "    The replay buffer returns the newly added image with a probability of $0.5$.\n",
        "    Otherwise, it sends an older generated image and replaces the older image\n",
        "    with the newly generated image.\n",
        "\n",
        "    This is done to reduce model oscillation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_size: int = 50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data: torch.Tensor):\n",
        "        \"\"\"Add/retrieve an image\"\"\"\n",
        "        data = data.detach()\n",
        "        res = []\n",
        "        for element in data:\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                res.append(element)\n",
        "            else:\n",
        "                if random.uniform(0, 1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    res.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    res.append(element)\n",
        "        return torch.stack(res)"
      ],
      "metadata": {
        "id": "0qp4IMNqq3R9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Configs(BaseConfigs):\n",
        "    \"\"\"## Configurations\"\"\"\n",
        "\n",
        "    # `DeviceConfigs` will pick a GPU if available\n",
        "    device: torch.device = DeviceConfigs()\n",
        "\n",
        "    # Hyper-parameters\n",
        "    epochs: int = 200\n",
        "    dataset_name: str = 'monet2photo'\n",
        "    batch_size: int = 1\n",
        "\n",
        "    data_loader_workers = 8\n",
        "\n",
        "    learning_rate = 0.0002\n",
        "    adam_betas = (0.5, 0.999)\n",
        "    decay_start = 100\n",
        "\n",
        "    # The paper suggests using a least-squares loss instead of\n",
        "    # negative log-likelihood, at it is found to be more stable.\n",
        "    gan_loss = torch.nn.MSELoss()\n",
        "\n",
        "    # L1 loss is used for cycle loss and identity loss\n",
        "    cycle_loss = torch.nn.L1Loss()\n",
        "    identity_loss = torch.nn.L1Loss()\n",
        "\n",
        "    # Image dimensions\n",
        "    img_height = 256\n",
        "    img_width = 256\n",
        "    img_channels = 3\n",
        "\n",
        "    # Number of residual blocks in the generator\n",
        "    n_residual_blocks = 9\n",
        "\n",
        "    # Loss coefficients\n",
        "    cyclic_loss_coefficient = 10.0\n",
        "    identity_loss_coefficient = 5.\n",
        "\n",
        "    sample_interval = 500\n",
        "\n",
        "    # Models\n",
        "    generator_xy: GeneratorResNet\n",
        "    generator_yx: GeneratorResNet\n",
        "    discriminator_x: Discriminator\n",
        "    discriminator_y: Discriminator\n",
        "\n",
        "    # Optimizers\n",
        "    generator_optimizer: torch.optim.Adam\n",
        "    discriminator_optimizer: torch.optim.Adam\n",
        "\n",
        "    # Learning rate schedules\n",
        "    generator_lr_scheduler: torch.optim.lr_scheduler.LambdaLR\n",
        "    discriminator_lr_scheduler: torch.optim.lr_scheduler.LambdaLR\n",
        "\n",
        "    # Data loaders\n",
        "    dataloader: DataLoader\n",
        "    valid_dataloader: DataLoader\n",
        "\n",
        "    def sample_images(self, n: int):\n",
        "        \"\"\"Generate samples from test set and save them\"\"\"\n",
        "        batch = next(iter(self.valid_dataloader))\n",
        "        self.generator_xy.eval()\n",
        "        self.generator_yx.eval()\n",
        "        with torch.no_grad():\n",
        "            data_x, data_y = batch['x'].to(self.generator_xy.device), batch['y'].to(self.generator_yx.device)\n",
        "            gen_y = self.generator_xy(data_x)\n",
        "            gen_x = self.generator_yx(data_y)\n",
        "\n",
        "            # Arrange images along x-axis\n",
        "            data_x = make_grid(data_x, nrow=5, normalize=True)\n",
        "            data_y = make_grid(data_y, nrow=5, normalize=True)\n",
        "            gen_x = make_grid(gen_x, nrow=5, normalize=True)\n",
        "            gen_y = make_grid(gen_y, nrow=5, normalize=True)\n",
        "\n",
        "            # Arrange images along y-axis\n",
        "            image_grid = torch.cat((data_x, gen_y, data_y, gen_x), 1)\n",
        "\n",
        "        # Show samples\n",
        "        plot_image(image_grid)\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"\n",
        "        ## Initialize models and data loaders\n",
        "        \"\"\"\n",
        "        input_shape = (self.img_channels, self.img_height, self.img_width)\n",
        "\n",
        "        # Create the models\n",
        "        self.generator_xy = GeneratorResNet(self.img_channels, self.n_residual_blocks).to(self.device)\n",
        "        self.generator_yx = GeneratorResNet(self.img_channels, self.n_residual_blocks).to(self.device)\n",
        "        self.discriminator_x = Discriminator(input_shape).to(self.device)\n",
        "        self.discriminator_y = Discriminator(input_shape).to(self.device)\n",
        "\n",
        "        # Create the optmizers\n",
        "        self.generator_optimizer = torch.optim.Adam(\n",
        "            itertools.chain(self.generator_xy.parameters(), self.generator_yx.parameters()),\n",
        "            lr=self.learning_rate, betas=self.adam_betas)\n",
        "        self.discriminator_optimizer = torch.optim.Adam(\n",
        "            itertools.chain(self.discriminator_x.parameters(), self.discriminator_y.parameters()),\n",
        "            lr=self.learning_rate, betas=self.adam_betas)\n",
        "\n",
        "        # Create the learning rate schedules.\n",
        "        # The learning rate stars flat until `decay_start` epochs,\n",
        "        # and then linearly reduce to $0$ at end of training.\n",
        "        decay_epochs = self.epochs - self.decay_start\n",
        "        self.generator_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "            self.generator_optimizer, lr_lambda=lambda e: 1.0 - max(0, e - self.decay_start) / decay_epochs)\n",
        "        self.discriminator_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "            self.discriminator_optimizer, lr_lambda=lambda e: 1.0 - max(0, e - self.decay_start) / decay_epochs)\n",
        "\n",
        "        # Image transformations\n",
        "        transforms_ = [\n",
        "            transforms.Resize(int(self.img_height * 1.12), InterpolationMode.BICUBIC),\n",
        "            transforms.RandomCrop((self.img_height, self.img_width)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "\n",
        "        # Training data loader\n",
        "        self.dataloader = DataLoader(\n",
        "            ImageDataset(self.dataset_name, transforms_, 'train'),\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.data_loader_workers,\n",
        "        )\n",
        "\n",
        "        # Validation data loader\n",
        "        self.valid_dataloader = DataLoader(\n",
        "            ImageDataset(self.dataset_name, transforms_, \"test\"),\n",
        "            batch_size=5,\n",
        "            shuffle=True,\n",
        "            num_workers=self.data_loader_workers,\n",
        "        )"
      ],
      "metadata": {
        "id": "9f9dzsOzrBtb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        ## Training\n",
        "\n",
        "        We aim to solve:\n",
        "        $$G^{*}, F^{*} = \\arg \\min_{G,F} \\max_{D_X, D_Y} \\mathcal{L}(G, F, D_X, D_Y)$$\n",
        "\n",
        "        where,\n",
        "        $G$ translates images from $X \\rightarrow Y$,\n",
        "        $F$ translates images from $Y \\rightarrow X$,\n",
        "        $D_X$ tests if images are from $X$ space,\n",
        "        $D_Y$ tests if images are from $Y$ space, and\n",
        "\n",
        "        \\begin{align}\n",
        "        \\mathcal{L}(G, F, D_X, D_Y)\n",
        "            &= \\mathcal{L}_{GAN}(G, D_Y, X, Y) \\\\\n",
        "            &+ \\mathcal{L}_{GAN}(F, D_X, Y, X) \\\\\n",
        "            &+ \\lambda_1 \\mathcal{L}_{cyc}(G, F) \\\\\n",
        "            &+ \\lambda_2 \\mathcal{L}_{identity}(G, F) \\\\\n",
        "        \\\\\n",
        "        \\mathcal{L}_{GAN}(G, F, D_Y, X, Y)\n",
        "            &= \\mathbb{E}_{y \\sim p_{data}(y)} \\Big[log D_Y(y)\\Big] \\\\\n",
        "            &+ \\mathbb{E}_{x \\sim p_{data}(x)} \\bigg[log\\Big(1 - D_Y(G(x))\\Big)\\bigg] \\\\\n",
        "            &+ \\mathbb{E}_{x \\sim p_{data}(x)} \\Big[log D_X(x)\\Big] \\\\\n",
        "            &+ \\mathbb{E}_{y \\sim p_{data}(y)} \\bigg[log\\Big(1 - D_X(F(y))\\Big)\\bigg] \\\\\n",
        "        \\\\\n",
        "        \\mathcal{L}_{cyc}(G, F)\n",
        "            &= \\mathbb{E}_{x \\sim p_{data}(x)} \\Big[\\lVert F(G(x)) - x \\lVert_1\\Big] \\\\\n",
        "            &+ \\mathbb{E}_{y \\sim p_{data}(y)} \\Big[\\lVert G(F(y)) - y \\rVert_1\\Big] \\\\\n",
        "        \\\\\n",
        "        \\mathcal{L}_{identity}(G, F)\n",
        "            &= \\mathbb{E}_{x \\sim p_{data}(x)} \\Big[\\lVert F(x) - x \\lVert_1\\Big] \\\\\n",
        "            &+ \\mathbb{E}_{y \\sim p_{data}(y)} \\Big[\\lVert G(y) - y \\rVert_1\\Big] \\\\\n",
        "        \\end{align}\n",
        "\n",
        "        $\\mathcal{L}_{GAN}$ is the generative adversarial loss from the original\n",
        "        GAN paper.\n",
        "\n",
        "        $\\mathcal{L}_{cyc}$ is the cyclic loss, where we try to get $F(G(x))$ to be similar to $x$,\n",
        "        and $G(F(y))$ to be similar to $y$.\n",
        "        Basically if the two generators (transformations) are applied in series it should give back the\n",
        "        original image.\n",
        "        This is the main contribution of this paper.\n",
        "        It trains the generators to generate an image of the other distribution that is similar to\n",
        "        the original image.\n",
        "        Without this loss $G(x)$ could generate anything that's from the distribution of $Y$.\n",
        "        Now it needs to generate something from the distribution of $Y$ but still has properties of $x$,\n",
        "        so that $F(G(x)$ can re-generate something like $x$.\n",
        "\n",
        "        $\\mathcal{L}_{cyc}$ is the identity loss.\n",
        "        This was used to encourage the mapping to preserve color composition between\n",
        "        the input and the output.\n",
        "\n",
        "        To solve $$G^*, F^*$$,\n",
        "        discriminators $D_X$ and $D_Y$ should **ascend** on the gradient,\n",
        "\n",
        "        \\begin{align}\n",
        "        \\nabla_{\\theta_{D_X, D_Y}} \\frac{1}{m} \\sum_{i=1}^m\n",
        "        &\\Bigg[\n",
        "        \\log D_Y\\Big(y^{(i)}\\Big) \\\\\n",
        "        &+ \\log \\Big(1 - D_Y\\Big(G\\Big(x^{(i)}\\Big)\\Big)\\Big) \\\\\n",
        "        &+ \\log D_X\\Big(x^{(i)}\\Big) \\\\\n",
        "        & +\\log\\Big(1 - D_X\\Big(F\\Big(y^{(i)}\\Big)\\Big)\\Big)\n",
        "        \\Bigg]\n",
        "        \\end{align}\n",
        "\n",
        "        That is descend on *negative* log-likelihood loss.\n",
        "\n",
        "        In order to stabilize the training the negative log- likelihood objective\n",
        "        was replaced by a least-squared loss -\n",
        "        the least-squared error of discriminator, labelling real images with 1,\n",
        "        and generated images with 0.\n",
        "        So we want to descend on the gradient,\n",
        "\n",
        "        \\begin{align}\n",
        "        \\nabla_{\\theta_{D_X, D_Y}} \\frac{1}{m} \\sum_{i=1}^m\n",
        "        &\\Bigg[\n",
        "            \\bigg(D_Y\\Big(y^{(i)}\\Big) - 1\\bigg)^2 \\\\\n",
        "            &+ D_Y\\Big(G\\Big(x^{(i)}\\Big)\\Big)^2 \\\\\n",
        "            &+ \\bigg(D_X\\Big(x^{(i)}\\Big) - 1\\bigg)^2 \\\\\n",
        "            &+ D_X\\Big(F\\Big(y^{(i)}\\Big)\\Big)^2\n",
        "        \\Bigg]\n",
        "        \\end{align}\n",
        "\n",
        "        We use least-squares for generators also.\n",
        "        The generators should *descend* on the gradient,\n",
        "\n",
        "        \\begin{align}\n",
        "        \\nabla_{\\theta_{F, G}} \\frac{1}{m} \\sum_{i=1}^m\n",
        "        &\\Bigg[\n",
        "            \\bigg(D_Y\\Big(G\\Big(x^{(i)}\\Big)\\Big) - 1\\bigg)^2 \\\\\n",
        "            &+ \\bigg(D_X\\Big(F\\Big(y^{(i)}\\Big)\\Big) - 1\\bigg)^2 \\\\\n",
        "            &+ \\mathcal{L}_{cyc}(G, F)\n",
        "            + \\mathcal{L}_{identity}(G, F)\n",
        "        \\Bigg]\n",
        "        \\end{align}\n",
        "\n",
        "        We use `generator_xy` for $G$ and `generator_yx` for $F$.\n",
        "        We use `discriminator_x` for $D_X$ and `discriminator_y` for $D_Y$.\n",
        "        \"\"\"\n",
        "\n",
        "        # Replay buffers to keep generated samples\n",
        "        gen_x_buffer = ReplayBuffer()\n",
        "        gen_y_buffer = ReplayBuffer()\n",
        "\n",
        "        # Loop through epochs\n",
        "        for epoch in monit.loop(self.epochs):\n",
        "            # Loop through the dataset\n",
        "            for i, batch in monit.enum('Train', self.dataloader):\n",
        "                # Move images to the device\n",
        "                data_x, data_y = batch['x'].to(self.device), batch['y'].to(self.device)\n",
        "\n",
        "                # true labels equal to $1$\n",
        "                true_labels = torch.ones(data_x.size(0), *self.discriminator_x.output_shape,\n",
        "                                         device=self.device, requires_grad=False)\n",
        "                # false labels equal to $0$\n",
        "                false_labels = torch.zeros(data_x.size(0), *self.discriminator_x.output_shape,\n",
        "                                           device=self.device, requires_grad=False)\n",
        "\n",
        "                # Train the generators.\n",
        "                # This returns the generated images.\n",
        "                gen_x, gen_y = self.optimize_generators(data_x, data_y, true_labels)\n",
        "\n",
        "                #  Train discriminators\n",
        "                self.optimize_discriminator(data_x, data_y,\n",
        "                                            gen_x_buffer.push_and_pop(gen_x), gen_y_buffer.push_and_pop(gen_y),\n",
        "                                            true_labels, false_labels)\n",
        "\n",
        "                # Save training statistics and increment the global step counter\n",
        "                tracker.save()\n",
        "                tracker.add_global_step(max(len(data_x), len(data_y)))\n",
        "\n",
        "                # Save images at intervals\n",
        "                batches_done = epoch * len(self.dataloader) + i\n",
        "                if batches_done % self.sample_interval == 0:\n",
        "                    # Save models when sampling images\n",
        "                    experiment.save_checkpoint()\n",
        "                    # Sample images\n",
        "                    self.sample_images(batches_done)\n",
        "\n",
        "            # Update learning rates\n",
        "            self.generator_lr_scheduler.step()\n",
        "            self.discriminator_lr_scheduler.step()\n",
        "            # New line\n",
        "            tracker.new_line()"
      ],
      "metadata": {
        "id": "0LrfpwD2rJGo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def optimize_generators(self, data_x: torch.Tensor, data_y: torch.Tensor, true_labels: torch.Tensor):\n",
        "        \"\"\"\n",
        "        ### Optimize the generators with identity, gan and cycle losses.\n",
        "        \"\"\"\n",
        "\n",
        "        #  Change to training mode\n",
        "        self.generator_xy.train()\n",
        "        self.generator_yx.train()\n",
        "\n",
        "        # Identity loss\n",
        "        # $$\\lVert F(G(x^{(i)})) - x^{(i)} \\lVert_1\\\n",
        "        #   \\lVert G(F(y^{(i)})) - y^{(i)} \\rVert_1$$\n",
        "        loss_identity = (self.identity_loss(self.generator_yx(data_x), data_x) +\n",
        "                         self.identity_loss(self.generator_xy(data_y), data_y))\n",
        "\n",
        "        # Generate images $G(x)$ and $F(y)$\n",
        "        gen_y = self.generator_xy(data_x)\n",
        "        gen_x = self.generator_yx(data_y)\n",
        "\n",
        "        # GAN loss\n",
        "        # $$\\bigg(D_Y\\Big(G\\Big(x^{(i)}\\Big)\\Big) - 1\\bigg)^2\n",
        "        #  + \\bigg(D_X\\Big(F\\Big(y^{(i)}\\Big)\\Big) - 1\\bigg)^2$$\n",
        "        loss_gan = (self.gan_loss(self.discriminator_y(gen_y), true_labels) +\n",
        "                    self.gan_loss(self.discriminator_x(gen_x), true_labels))\n",
        "\n",
        "        # Cycle loss\n",
        "        # $$\n",
        "        # \\lVert F(G(x^{(i)})) - x^{(i)} \\lVert_1 +\n",
        "        # \\lVert G(F(y^{(i)})) - y^{(i)} \\rVert_1\n",
        "        # $$\n",
        "        loss_cycle = (self.cycle_loss(self.generator_yx(gen_y), data_x) +\n",
        "                      self.cycle_loss(self.generator_xy(gen_x), data_y))\n",
        "\n",
        "        # Total loss\n",
        "        loss_generator = (loss_gan +\n",
        "                          self.cyclic_loss_coefficient * loss_cycle +\n",
        "                          self.identity_loss_coefficient * loss_identity)\n",
        "\n",
        "        # Take a step in the optimizer\n",
        "        self.generator_optimizer.zero_grad()\n",
        "        loss_generator.backward()\n",
        "        self.generator_optimizer.step()\n",
        "\n",
        "        # Log losses\n",
        "        tracker.add({'loss.generator': loss_generator,\n",
        "                     'loss.generator.cycle': loss_cycle,\n",
        "                     'loss.generator.gan': loss_gan,\n",
        "                     'loss.generator.identity': loss_identity})\n",
        "\n",
        "        # Return generated images\n",
        "        return gen_x, gen_y\n",
        "\n",
        "    def optimize_discriminator(self, data_x: torch.Tensor, data_y: torch.Tensor,\n",
        "                               gen_x: torch.Tensor, gen_y: torch.Tensor,\n",
        "                               true_labels: torch.Tensor, false_labels: torch.Tensor):\n",
        "        \"\"\"\n",
        "        ### Optimize the discriminators with gan loss.\n",
        "        \"\"\"\n",
        "\n",
        "        # GAN Loss\n",
        "        #\n",
        "        # \\begin{align}\n",
        "        # \\bigg(D_Y\\Big(y ^ {(i)}\\Big) - 1\\bigg) ^ 2\n",
        "        # + D_Y\\Big(G\\Big(x ^ {(i)}\\Big)\\Big) ^ 2 + \\\\\n",
        "        # \\bigg(D_X\\Big(x ^ {(i)}\\Big) - 1\\bigg) ^ 2\n",
        "        # + D_X\\Big(F\\Big(y ^ {(i)}\\Big)\\Big) ^ 2\n",
        "        # \\end{align}\n",
        "        loss_discriminator = (self.gan_loss(self.discriminator_x(data_x), true_labels) +\n",
        "                              self.gan_loss(self.discriminator_x(gen_x), false_labels) +\n",
        "                              self.gan_loss(self.discriminator_y(data_y), true_labels) +\n",
        "                              self.gan_loss(self.discriminator_y(gen_y), false_labels))\n",
        "\n",
        "        # Take a step in the optimizer\n",
        "        self.discriminator_optimizer.zero_grad()\n",
        "        loss_discriminator.backward()\n",
        "        self.discriminator_optimizer.step()\n",
        "\n",
        "        # Log losses\n",
        "        tracker.add({'loss.discriminator': loss_discriminator})"
      ],
      "metadata": {
        "id": "3L1ZoFmGrOG8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    \"\"\"\n",
        "    ## Train Cycle GAN\n",
        "    \"\"\"\n",
        "    # Create configurations\n",
        "    conf = Configs()\n",
        "    # Create an experiment\n",
        "    experiment.create(name='cycle_gan')\n",
        "    # Calculate configurations.\n",
        "    # It will calculate `conf.run` and all other configs required by it.\n",
        "    experiment.configs(conf, {'dataset_name': 'summer2winter_yosemite'})\n",
        "    conf.initialize()\n",
        "\n",
        "    # Register models for saving and loading.\n",
        "    # `get_modules` gives a dictionary of `nn.Modules` in `conf`.\n",
        "    # You can also specify a custom dictionary of models.\n",
        "    experiment.add_pytorch_models(get_modules(conf))\n",
        "    # Start and watch the experiment\n",
        "    with experiment.start():\n",
        "        # Run the training\n",
        "        conf.run()"
      ],
      "metadata": {
        "id": "IOdPxddwrSFa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(img: torch.Tensor):\n",
        "    \"\"\"\n",
        "    ### Plot an image with matplotlib\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot as plt\n",
        "\n",
        "    # Move tensor to CPU\n",
        "    img = img.cpu()\n",
        "    # Get min and max values of the image for normalization\n",
        "    img_min, img_max = img.min(), img.max()\n",
        "    # Scale image values to be [0...1]\n",
        "    img = (img - img_min) / (img_max - img_min + 1e-5)\n",
        "    # We have to change the order of dimensions to HWC.\n",
        "    img = img.permute(1, 2, 0)\n",
        "    # Show Image\n",
        "    plt.imshow(img)\n",
        "    # We don't need axes\n",
        "    plt.axis('off')\n",
        "    # Display\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4rwd3u5IrTj3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "    \"\"\"\n",
        "    ## Evaluate trained Cycle GAN\n",
        "    \"\"\"\n",
        "    # Set the run UUID from the training run\n",
        "    trained_run_uuid = 'f73c1164184711eb9190b74249275441'\n",
        "    # Create configs object\n",
        "    conf = Configs()\n",
        "    # Create experiment\n",
        "    experiment.create(name='cycle_gan_inference')\n",
        "    # Load hyper parameters set for training\n",
        "    conf_dict = experiment.load_configs(trained_run_uuid)\n",
        "    # Calculate configurations. We specify the generators `'generator_xy', 'generator_yx'`\n",
        "    # so that it only loads those and their dependencies.\n",
        "    # Configs like `device` and `img_channels` will be calculated, since these are required by\n",
        "    # `generator_xy` and `generator_yx`.\n",
        "    #\n",
        "    # If you want other parameters like `dataset_name` you should specify them here.\n",
        "    # If you specify nothing, all the configurations will be calculated, including data loaders.\n",
        "    # Calculation of configurations and their dependencies will happen when you call `experiment.start`\n",
        "    experiment.configs(conf, conf_dict)\n",
        "    conf.initialize()\n",
        "\n",
        "    # Register models for saving and loading.\n",
        "    # `get_modules` gives a dictionary of `nn.Modules` in `conf`.\n",
        "    # You can also specify a custom dictionary of models.\n",
        "    experiment.add_pytorch_models(get_modules(conf))\n",
        "    # Specify which run to load from.\n",
        "    # Loading will actually happen when you call `experiment.start`\n",
        "    experiment.load(trained_run_uuid)\n",
        "\n",
        "    # Start the experiment\n",
        "    with experiment.start():\n",
        "        # Image transformations\n",
        "        transforms_ = [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "\n",
        "        # Load your own data. Here we try the test set.\n",
        "        # I was trying with Yosemite photos, they look awesome.\n",
        "        # You can use `conf.dataset_name`, if you specified `dataset_name` as something you wanted to be calculated\n",
        "        # in the call to `experiment.configs`\n",
        "        dataset = ImageDataset(conf.dataset_name, transforms_, 'train')\n",
        "        # Get an image from dataset\n",
        "        x_image = dataset[10]['x']\n",
        "        # Display the image\n",
        "        plot_image(x_image)\n",
        "\n",
        "        # Evaluation mode\n",
        "        conf.generator_xy.eval()\n",
        "        conf.generator_yx.eval()\n",
        "\n",
        "        # We don't need gradients\n",
        "        with torch.no_grad():\n",
        "            # Add batch dimension and move to the device we use\n",
        "            data = x_image.unsqueeze(0).to(conf.device)\n",
        "            generated_y = conf.generator_xy(data)\n",
        "\n",
        "        # Display the generated image.\n",
        "        plot_image(generated_y[0].cpu())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()\n",
        "    # evaluate()"
      ],
      "metadata": {
        "id": "0Xqa-KL7e_Tr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}